{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1feb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T08:54:15.181383Z",
     "start_time": "2024-04-17T08:54:13.428841Z"
    }
   },
   "outputs": [],
   "source": [
    "import isaacgym\n",
    "from legged_gym.envs import *\n",
    "from legged_gym.utils import  get_args, export_policy_as_jit, task_registry, Logger\n",
    "from isaacgym.torch_utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from rsl_rl.runners import OnPolicyRunner, OnPolicyRunner_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc81c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:41:21.114863Z",
     "start_time": "2023-10-10T13:41:21.102236Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class A():\n",
    "    class Transition():\n",
    "        def __init__(self, **kwargs):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            self.extra_info={}\n",
    "            for key in kwargs:\n",
    "                print(key)\n",
    "                self.extra_info[key] = None\n",
    "            # self.observations_h = None\n",
    "            # self.body_vel = None\n",
    "            # self.observations_f = None\n",
    "            print(self.extra_info)\n",
    "\n",
    "        def clear(self):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            for key in self.extra_info:\n",
    "                print(key)\n",
    "                self.extra_info[key] = None\n",
    "    \n",
    "\n",
    "    def __init__(self, num_envs, num_transitions_per_env, device='cpu', **kwargs):\n",
    "        self.device = device\n",
    "        self.num_envs = num_envs\n",
    "        self.num_transitions_per_env = num_transitions_per_env\n",
    "        self.extra_info={}\n",
    "                \n",
    "        for key, value in kwargs.items():\n",
    "            if key.endswith(\"shape\"):\n",
    "                print(key, \"/\", key.rsplit(\"_\",1), \":\", value)\n",
    "                self.extra_info[key.rsplit(\"_\",1)[0]] = torch.zeros(num_transitions_per_env, num_envs, *value, device=self.device)\n",
    "                \n",
    "    def get_extra(self):\n",
    "        for k,d in self.extra_info.items():\n",
    "            print(k, d.shape, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9927b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:41:21.547898Z",
     "start_time": "2023-10-10T13:41:21.540693Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "a = A(15,24,device=\"cpu\",\n",
    "      obs_shape=[70], \n",
    "      privileged_obs_shape=[70], \n",
    "      actions_shape=[12], \n",
    "      obs_h_shape=[70*10],\n",
    "      obs_f_shape=[70], \n",
    "      body_vel_shape=[3])\n",
    "b = A.Transition(obs_h=[], obs_f=[], body_vel=[])\n",
    "b.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f1f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:20:46.152836Z",
     "start_time": "2023-10-10T13:20:46.136217Z"
    }
   },
   "outputs": [],
   "source": [
    "a.get_extra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cf859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:34:23.362692Z",
     "start_time": "2023-10-11T09:34:23.318960Z"
    },
    "code_folding": [
     0,
     121,
     141,
     157
    ]
   },
   "outputs": [],
   "source": [
    "class RolloutStorage2():\n",
    "    class Transition():\n",
    "        def __init__(self, **kwargs):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            self.extra_info={}\n",
    "            for key in kwargs:\n",
    "                print(key)\n",
    "                self.extra_info[key] = None\n",
    "\n",
    "            self.obs_h = None\n",
    "            self.body_vel = None\n",
    "            self.obs_f = None\n",
    "\n",
    "        def clear(self):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            for key in self.extra_info:\n",
    "                print(key)\n",
    "                self.extra_info[key] = None\n",
    "                \n",
    "            self.obs_h = None\n",
    "            self.body_vel = None\n",
    "            self.obs_f = None\n",
    "\n",
    "    def __init__(self, num_envs, num_transitions_per_env, obs_shape, privileged_obs_shape, actions_shape, \n",
    "                 obs_h_sp, obs_f_sp, body_vel_sp, device='cpu', **kwargs):\n",
    "        self.device = device\n",
    "        self.obs_shape = obs_shape\n",
    "        self.privileged_obs_shape = privileged_obs_shape\n",
    "        self.actions_shape = actions_shape\n",
    "\n",
    "        # Core\n",
    "        self.observations = torch.zeros(num_transitions_per_env, num_envs, *obs_shape, device=self.device)\n",
    "        if privileged_obs_shape[0] is not None:\n",
    "            self.privileged_observations = torch.zeros(num_transitions_per_env, num_envs, *privileged_obs_shape, \n",
    "                                                       device=self.device)\n",
    "        else:\n",
    "            self.privileged_observations = None\n",
    "        self.rewards = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.actions = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "        self.dones = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device).byte()\n",
    "\n",
    "        # For PPO\n",
    "        self.actions_log_prob = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.values = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.returns = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.advantages = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.mu = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "        self.sigma = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "\n",
    "        self.num_transitions_per_env = num_transitions_per_env\n",
    "        self.num_envs = num_envs\n",
    "\n",
    "        # rnn\n",
    "        self.saved_hidden_states_a = None\n",
    "        self.saved_hidden_states_c = None\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        # For other info (dream waq)\n",
    "        self.extra_info={}\n",
    "        for key, value in kwargs.items():\n",
    "            if key.endswith(\"shape\"):\n",
    "                print(key, \"/\", key.rsplit(\"_\",1), \":\", value)\n",
    "                self.extra_info[key.rsplit(\"_\",1)[0]] = torch.zeros(num_transitions_per_env, num_envs, \n",
    "                                                                    *value, device=self.device)\n",
    "\n",
    "        self.obs_h = torch.zeros(num_transitions_per_env, num_envs, *obs_h_sp, device=self.device)\n",
    "        self.obs_f = torch.zeros(num_transitions_per_env, num_envs, *obs_f_sp, device=self.device)\n",
    "        self.body_vel = torch.zeros(num_transitions_per_env, num_envs, *body_vel_sp, device=self.device)\n",
    "\n",
    "    def add_transitions(self, transition: Transition):\n",
    "        if self.step >= self.num_transitions_per_env:\n",
    "            raise AssertionError(\"Rollout buffer overflow\")\n",
    "        self.observations[self.step].copy_(transition.observations)\n",
    "        if self.privileged_observations is not None: self.privileged_observations[self.step].copy_(transition.critic_observations)\n",
    "        self.actions[self.step].copy_(transition.actions)\n",
    "        self.rewards[self.step].copy_(transition.rewards.view(-1, 1))\n",
    "        self.dones[self.step].copy_(transition.dones.view(-1, 1))\n",
    "        self.values[self.step].copy_(transition.values)\n",
    "        self.actions_log_prob[self.step].copy_(transition.actions_log_prob.view(-1, 1))\n",
    "        self.mu[self.step].copy_(transition.action_mean)\n",
    "        self.sigma[self.step].copy_(transition.action_sigma)\n",
    "        self._save_hidden_states(transition.hidden_states)\n",
    "\n",
    "        for key in self.extra_info:\n",
    "            self.extra_info[key][self.step].copy_(transition.extra_info[key])\n",
    "        self.obs_h[self.step].copy_(transition.observations_h)\n",
    "        self.body_vel[self.step].copy_(transition.body_vel)\n",
    "        self.obs_f[self.step].copy_(transition.observations_f)\n",
    "        \n",
    "        print(\"self.step:\", self.step)\n",
    "        for key in self.extra_info:\n",
    "            print(key)\n",
    "            print(self.extra_info[key][self.step])\n",
    "        \n",
    "        print(\"self.obs_h:\\n\", self.obs_h[self.step])\n",
    "        print(\"self.obs_f:\\n\", self.obs_f[self.step])\n",
    "        print(\"self.body_vel:\\n\", self.body_vel[self.step])\n",
    "            \n",
    "        self.step += 1\n",
    "\n",
    "    def _save_hidden_states(self, hidden_states):\n",
    "        if hidden_states is None or hidden_states==(None, None):\n",
    "            return\n",
    "        # make a tuple out of GRU hidden state sto match the LSTM format\n",
    "        hid_a = hidden_states[0] if isinstance(hidden_states[0], tuple) else (hidden_states[0],)\n",
    "        hid_c = hidden_states[1] if isinstance(hidden_states[1], tuple) else (hidden_states[1],)\n",
    "\n",
    "        # initialize if needed\n",
    "        if self.saved_hidden_states_a is None:\n",
    "            self.saved_hidden_states_a = [torch.zeros(self.observations.shape[0], *hid_a[i].shape, device=self.device) for i in range(len(hid_a))]\n",
    "            self.saved_hidden_states_c = [torch.zeros(self.observations.shape[0], *hid_c[i].shape, device=self.device) for i in range(len(hid_c))]\n",
    "        # copy the states\n",
    "        for i in range(len(hid_a)):\n",
    "            self.saved_hidden_states_a[i][self.step].copy_(hid_a[i])\n",
    "            self.saved_hidden_states_c[i][self.step].copy_(hid_c[i])\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.step = 0\n",
    "\n",
    "    def compute_returns(self, last_values, gamma, lam):\n",
    "        advantage = 0\n",
    "        for step in reversed(range(self.num_transitions_per_env)):\n",
    "            if step == self.num_transitions_per_env - 1:\n",
    "                next_values = last_values\n",
    "            else:\n",
    "                next_values = self.values[step + 1]\n",
    "            next_is_not_terminal = 1.0 - self.dones[step].float()\n",
    "            delta = self.rewards[step] + next_is_not_terminal * gamma * next_values - self.values[step]\n",
    "            advantage = delta + next_is_not_terminal * gamma * lam * advantage\n",
    "            self.returns[step] = advantage + self.values[step]\n",
    "\n",
    "        # Compute and normalize the advantages\n",
    "        self.advantages = self.returns - self.values\n",
    "        self.advantages = (self.advantages - self.advantages.mean()) / (self.advantages.std() + 1e-8)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        done = self.dones\n",
    "        done[-1] = 1\n",
    "        flat_dones = done.permute(1, 0, 2).reshape(-1, 1)\n",
    "        done_indices = torch.cat((flat_dones.new_tensor([-1], dtype=torch.int64), flat_dones.nonzero(as_tuple=False)[:, 0]))\n",
    "        trajectory_lengths = (done_indices[1:] - done_indices[:-1])\n",
    "        return trajectory_lengths.float().mean(), self.rewards.mean()\n",
    "\n",
    "    def mini_batch_generator(self, num_mini_batches, num_epochs=8):\n",
    "        batch_size = self.num_envs * self.num_transitions_per_env\n",
    "        mini_batch_size = batch_size // num_mini_batches\n",
    "        indices = torch.randperm(num_mini_batches*mini_batch_size, requires_grad=False, device=self.device)\n",
    "\n",
    "        observations = self.observations.flatten(0, 1)\n",
    "        if self.privileged_observations is not None:\n",
    "            critic_observations = self.privileged_observations.flatten(0, 1)\n",
    "        else:\n",
    "            critic_observations = observations\n",
    "\n",
    "        print(\"flatten\")\n",
    "        extra_flat = {}\n",
    "        for key in self.extra_info:\n",
    "            extra_flat[key] = self.extra_info[key].flatten(0, 1)\n",
    "            print(key)\n",
    "            print(extra_flat[key])\n",
    "\n",
    "        observations_h=self.obs_h.flatten(0, 1)\n",
    "        observations_f = self.obs_f.flatten(0, 1)\n",
    "        body_vel = self.body_vel.flatten(0, 1)\n",
    "\n",
    "        actions = self.actions.flatten(0, 1)\n",
    "        values = self.values.flatten(0, 1)\n",
    "        returns = self.returns.flatten(0, 1)\n",
    "        old_actions_log_prob = self.actions_log_prob.flatten(0, 1)\n",
    "        advantages = self.advantages.flatten(0, 1)\n",
    "        old_mu = self.mu.flatten(0, 1)\n",
    "        old_sigma = self.sigma.flatten(0, 1)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(num_mini_batches):\n",
    "                start = i*mini_batch_size\n",
    "                end = (i+1)*mini_batch_size\n",
    "                batch_idx = indices[start:end]\n",
    "\n",
    "                obs_batch = observations[batch_idx]\n",
    "                critic_observations_batch = critic_observations[batch_idx]\n",
    "                actions_batch = actions[batch_idx]\n",
    "                target_values_batch = values[batch_idx]\n",
    "                returns_batch = returns[batch_idx]\n",
    "                old_actions_log_prob_batch = old_actions_log_prob[batch_idx]\n",
    "                advantages_batch = advantages[batch_idx]\n",
    "                old_mu_batch = old_mu[batch_idx]\n",
    "                old_sigma_batch = old_sigma[batch_idx]\n",
    "\n",
    "                obs_h_batch = observations_h[batch_idx]\n",
    "                obs_f_batch = observations_f[batch_idx]\n",
    "                body_vel_batch = body_vel[batch_idx]\n",
    "                \n",
    "                extra_batch = {}\n",
    "                for key in extra_flat:\n",
    "                    extra_batch[key] = extra_flat[key][batch_idx]\n",
    "                print(\"extra_batch:\\n\", extra_batch)\n",
    "                extra_batch_tuple = tuple(extra_batch.values())\n",
    "                print(\"extra_batch_tuple:\\n\", extra_batch_tuple)\n",
    "\n",
    "                yield obs_batch, critic_observations_batch, actions_batch, target_values_batch, advantages_batch, returns_batch, \\\n",
    "                       old_actions_log_prob_batch, old_mu_batch, old_sigma_batch, \\\n",
    "                (None, None), None, obs_h_batch, obs_f_batch, body_vel_batch, extra_batch_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b2a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:51:47.483626Z",
     "start_time": "2023-10-11T12:51:47.449024Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class RolloutStorage():\n",
    "    class Transition():\n",
    "        def __init__(self, **kwargs):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            self.extra_info={}\n",
    "            for key in kwargs:\n",
    "                print(key)\n",
    "                self.extra_info[key] = None\n",
    "\n",
    "        def clear(self):\n",
    "            self.observations = None\n",
    "            self.critic_observations = None\n",
    "            self.actions = None\n",
    "            self.rewards = None\n",
    "            self.dones = None\n",
    "            self.values = None\n",
    "            self.actions_log_prob = None\n",
    "            self.action_mean = None\n",
    "            self.action_sigma = None\n",
    "            self.hidden_states = None\n",
    "\n",
    "            for key in self.extra_info:\n",
    "                self.extra_info[key] = None\n",
    "\n",
    "    def __init__(self, num_envs, num_transitions_per_env, obs_shape, privileged_obs_shape, actions_shape, \n",
    "                 device='cpu', **kwargs):\n",
    "        self.device = device\n",
    "        self.obs_shape = obs_shape\n",
    "        self.privileged_obs_shape = privileged_obs_shape\n",
    "        self.actions_shape = actions_shape\n",
    "\n",
    "        # Core\n",
    "        self.observations = torch.zeros(num_transitions_per_env, num_envs, *obs_shape, device=self.device)\n",
    "        if privileged_obs_shape[0] is not None:\n",
    "            self.privileged_observations = torch.zeros(num_transitions_per_env, num_envs, *privileged_obs_shape, \n",
    "                                                       device=self.device)\n",
    "        else:\n",
    "            self.privileged_observations = None\n",
    "        self.rewards = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.actions = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "        self.dones = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device).byte()\n",
    "\n",
    "        # For PPO\n",
    "        self.actions_log_prob = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.values = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.returns = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.advantages = torch.zeros(num_transitions_per_env, num_envs, 1, device=self.device)\n",
    "        self.mu = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "        self.sigma = torch.zeros(num_transitions_per_env, num_envs, *actions_shape, device=self.device)\n",
    "\n",
    "        self.num_transitions_per_env = num_transitions_per_env\n",
    "        self.num_envs = num_envs\n",
    "\n",
    "        # rnn\n",
    "        self.saved_hidden_states_a = None\n",
    "        self.saved_hidden_states_c = None\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "        # For other info (dream waq)\n",
    "        self.extra_info={}\n",
    "        for key, value in kwargs.items():\n",
    "            if key.endswith(\"shape\"):\n",
    "                print(key, \"/\", key.rsplit(\"_\",1), \":\", value)\n",
    "                self.extra_info[key.rsplit(\"_\",1)[0]] = torch.zeros(num_transitions_per_env, num_envs, \n",
    "                                                                    *value, device=self.device)\n",
    "\n",
    "    def add_transitions(self, transition: Transition):\n",
    "        if self.step >= self.num_transitions_per_env:\n",
    "            raise AssertionError(\"Rollout buffer overflow\")\n",
    "        self.observations[self.step].copy_(transition.observations)\n",
    "        if self.privileged_observations is not None: self.privileged_observations[self.step].copy_(transition.critic_observations)\n",
    "        self.actions[self.step].copy_(transition.actions)\n",
    "        self.rewards[self.step].copy_(transition.rewards.view(-1, 1))\n",
    "        self.dones[self.step].copy_(transition.dones.view(-1, 1))\n",
    "        self.values[self.step].copy_(transition.values)\n",
    "        self.actions_log_prob[self.step].copy_(transition.actions_log_prob.view(-1, 1))\n",
    "        self.mu[self.step].copy_(transition.action_mean)\n",
    "        self.sigma[self.step].copy_(transition.action_sigma)\n",
    "        self._save_hidden_states(transition.hidden_states)\n",
    "\n",
    "        for key in self.extra_info:\n",
    "            self.extra_info[key][self.step].copy_(transition.extra_info[key])\n",
    "        \n",
    "#         print(\"self.step:\", self.step)\n",
    "#         for key in self.extra_info:\n",
    "#             print(key)\n",
    "#             print(self.extra_info[key][self.step])\n",
    "            \n",
    "        self.step += 1\n",
    "\n",
    "    def _save_hidden_states(self, hidden_states):\n",
    "        if hidden_states is None or hidden_states==(None, None):\n",
    "            return\n",
    "        # make a tuple out of GRU hidden state sto match the LSTM format\n",
    "        hid_a = hidden_states[0] if isinstance(hidden_states[0], tuple) else (hidden_states[0],)\n",
    "        hid_c = hidden_states[1] if isinstance(hidden_states[1], tuple) else (hidden_states[1],)\n",
    "\n",
    "        # initialize if needed\n",
    "        if self.saved_hidden_states_a is None:\n",
    "            self.saved_hidden_states_a = [torch.zeros(self.observations.shape[0], *hid_a[i].shape, device=self.device) for i in range(len(hid_a))]\n",
    "            self.saved_hidden_states_c = [torch.zeros(self.observations.shape[0], *hid_c[i].shape, device=self.device) for i in range(len(hid_c))]\n",
    "        # copy the states\n",
    "        for i in range(len(hid_a)):\n",
    "            self.saved_hidden_states_a[i][self.step].copy_(hid_a[i])\n",
    "            self.saved_hidden_states_c[i][self.step].copy_(hid_c[i])\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.step = 0\n",
    "\n",
    "    def compute_returns(self, last_values, gamma, lam):\n",
    "        advantage = 0\n",
    "        for step in reversed(range(self.num_transitions_per_env)):\n",
    "            if step == self.num_transitions_per_env - 1:\n",
    "                next_values = last_values\n",
    "            else:\n",
    "                next_values = self.values[step + 1]\n",
    "            next_is_not_terminal = 1.0 - self.dones[step].float()\n",
    "            delta = self.rewards[step] + next_is_not_terminal * gamma * next_values - self.values[step]\n",
    "            advantage = delta + next_is_not_terminal * gamma * lam * advantage\n",
    "            self.returns[step] = advantage + self.values[step]\n",
    "\n",
    "        # Compute and normalize the advantages\n",
    "        self.advantages = self.returns - self.values\n",
    "        self.advantages = (self.advantages - self.advantages.mean()) / (self.advantages.std() + 1e-8)\n",
    "\n",
    "    def get_statistics(self):\n",
    "        done = self.dones\n",
    "        done[-1] = 1\n",
    "        flat_dones = done.permute(1, 0, 2).reshape(-1, 1)\n",
    "        done_indices = torch.cat((flat_dones.new_tensor([-1], dtype=torch.int64), flat_dones.nonzero(as_tuple=False)[:, 0]))\n",
    "        trajectory_lengths = (done_indices[1:] - done_indices[:-1])\n",
    "        return trajectory_lengths.float().mean(), self.rewards.mean()\n",
    "\n",
    "    def mini_batch_generator(self, num_mini_batches, num_epochs=8):\n",
    "        batch_size = self.num_envs * self.num_transitions_per_env\n",
    "        mini_batch_size = batch_size // num_mini_batches\n",
    "        indices = torch.randperm(num_mini_batches*mini_batch_size, requires_grad=False, device=self.device)\n",
    "\n",
    "        observations = self.observations.flatten(0, 1)\n",
    "        if self.privileged_observations is not None:\n",
    "            critic_observations = self.privileged_observations.flatten(0, 1)\n",
    "        else:\n",
    "            critic_observations = observations\n",
    "\n",
    "        print(\"flatten\")\n",
    "        extra_flat = {}\n",
    "        for key in self.extra_info:\n",
    "            extra_flat[key] = self.extra_info[key].flatten(0, 1)\n",
    "            print(key)\n",
    "            print(extra_flat[key])\n",
    "\n",
    "        actions = self.actions.flatten(0, 1)\n",
    "        values = self.values.flatten(0, 1)\n",
    "        returns = self.returns.flatten(0, 1)\n",
    "        old_actions_log_prob = self.actions_log_prob.flatten(0, 1)\n",
    "        advantages = self.advantages.flatten(0, 1)\n",
    "        old_mu = self.mu.flatten(0, 1)\n",
    "        old_sigma = self.sigma.flatten(0, 1)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(num_mini_batches):\n",
    "                start = i*mini_batch_size\n",
    "                end = (i+1)*mini_batch_size\n",
    "                batch_idx = indices[start:end]\n",
    "\n",
    "                obs_batch = observations[batch_idx]\n",
    "                critic_observations_batch = critic_observations[batch_idx]\n",
    "                actions_batch = actions[batch_idx]\n",
    "                target_values_batch = values[batch_idx]\n",
    "                returns_batch = returns[batch_idx]\n",
    "                old_actions_log_prob_batch = old_actions_log_prob[batch_idx]\n",
    "                advantages_batch = advantages[batch_idx]\n",
    "                old_mu_batch = old_mu[batch_idx]\n",
    "                old_sigma_batch = old_sigma[batch_idx]\n",
    "\n",
    "                extra_batch = {}\n",
    "                for key in extra_flat:\n",
    "                    extra_batch[key] = extra_flat[key][batch_idx]\n",
    "                print(\"extra_batch:\\n\", extra_batch)\n",
    "                extra_batch_tuple = tuple(extra_batch.values())\n",
    "                print(\"extra_batch_tuple:\\n\", extra_batch_tuple)\n",
    "\n",
    "                yield obs_batch, critic_observations_batch, actions_batch, target_values_batch, advantages_batch, returns_batch, \\\n",
    "                       old_actions_log_prob_batch, old_mu_batch, old_sigma_batch, \\\n",
    "                (None, None), None, extra_batch_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942192e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T14:18:26.892635Z",
     "start_time": "2023-10-11T14:18:26.887650Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_storage(num_envs, num_transitions_per_env, actor_obs_shape, critic_obs_shape, action_shape,\n",
    "                 **kwargs):\n",
    "    extra = {}\n",
    "    for key, value in kwargs.items():\n",
    "        if key.endswith(\"shape\"):\n",
    "            print(key, \":\", value)\n",
    "            extra[key.rsplit(\"_\",1)[0]] = None\n",
    "    print(\"extra:\", extra)\n",
    "    storage = RolloutStorage(num_envs, num_transitions_per_env, actor_obs_shape, critic_obs_shape, action_shape,\n",
    "                            **kwargs)\n",
    "    transition = RolloutStorage.Transition(**extra)\n",
    "    return storage, transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d2667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T14:18:36.504423Z",
     "start_time": "2023-10-11T14:18:36.495821Z"
    }
   },
   "outputs": [],
   "source": [
    "ob_dim = 50\n",
    "ac_dim = 12\n",
    "num_transitions_per_env = 40\n",
    "num_envs = 24\n",
    "obs_h_shape = [50*10]\n",
    "obs_f_shape = [50]\n",
    "body_vel_shape = [3]\n",
    "storage, transition = init_storage(num_envs, num_transitions_per_env, [ob_dim], [ob_dim], [ac_dim],\n",
    "                                  obs_h_shape=[50*10], obs_f_shape=[50], body_vel_shape=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085ef7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T13:00:56.229957Z",
     "start_time": "2023-10-11T13:00:56.220147Z"
    }
   },
   "outputs": [],
   "source": [
    "storage = RolloutStorage(num_envs, num_transitions_per_env, [ob_dim], [ob_dim], [12], device=\"cpu\",\n",
    "                         obs_h_shape=obs_h_shape,obs_f_shape=obs_f_shape,  body_vel_shape=body_vel_shape)\n",
    "\n",
    "obd={\"obs_h\":None, \"obs_f\":None, \"body_vel\":None}\n",
    "print(obd.keys())\n",
    "\n",
    "transition = RolloutStorage.Transition(**obd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb758b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:27:13.279138Z",
     "start_time": "2023-10-11T12:27:13.261988Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    observations = torch.rand(num_envs, ob_dim)\n",
    "    critic_observations = observations\n",
    "    actions = torch.rand(num_envs, ac_dim)\n",
    "    rewards = torch.rand(num_envs)\n",
    "    dones = torch.zeros(num_envs, dtype=torch.bool)\n",
    "    values = torch.rand(num_envs, 1)\n",
    "    actions_log_prob = torch.rand(num_envs)\n",
    "    action_mean = torch.rand(num_envs, ac_dim)\n",
    "    action_sigma = torch.rand(num_envs, ac_dim)\n",
    "    \n",
    "    observations_h = torch.rand(num_envs, ob_dim*10)\n",
    "    observations_f = torch.rand(num_envs, ob_dim)\n",
    "    body_vel = torch.rand(num_envs, 3)\n",
    "    \n",
    "    transition.observations = observations\n",
    "    transition.critic_observations = critic_observations\n",
    "    transition.actions = actions\n",
    "    transition.rewards = rewards\n",
    "    transition.dones = dones\n",
    "    transition.values = values\n",
    "    transition.actions_log_prob = actions_log_prob\n",
    "    transition.action_mean = action_mean\n",
    "    transition.action_sigma = action_sigma\n",
    "    \n",
    "    for key in transition.extra_info:\n",
    "        if key == \"obs_h\":\n",
    "            transition.extra_info[key] = observations_h\n",
    "        if key == \"obs_f\":\n",
    "            transition.extra_info[key] = observations_f\n",
    "        if key == \"body_vel\":\n",
    "            transition.extra_info[key] = body_vel\n",
    "    \n",
    "    transition.what = body_vel\n",
    "#     print(\"what?\", transition.what)\n",
    "#     print(\"why?\", transition.why)\n",
    "    \n",
    "    storage.add_transitions(transition)\n",
    "    transition.clear()\n",
    "    \n",
    "storage.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b9718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:27:15.677751Z",
     "start_time": "2023-10-11T12:27:15.244977Z"
    }
   },
   "outputs": [],
   "source": [
    "num_mini_batches = 4\n",
    "num_learning_epochs = 4\n",
    "cnt = 0\n",
    "generator = storage.mini_batch_generator(num_mini_batches, num_learning_epochs)\n",
    "for obs_batch, critic_obs_batch, actions_batch, target_values_batch, advantages_batch, \\\n",
    "    returns_batch, old_actions_log_prob_batch, old_mu_batch, old_sigma_batch, \\\n",
    "    hid_states_batch, masks_batch, (obs_h_batch, obs_f_batch, body_vel_batch) in generator:\n",
    "    print(\"cnt:\", cnt)\n",
    "    print(\"actions_batch:\", actions_batch.shape, actions_batch)\n",
    "    print(\"obs_h_batch:\", obs_h_batch.shape, obs_h_batch)\n",
    "    print(\"obs_f_batch:\", obs_f_batch.shape, obs_f_batch)\n",
    "    print(\"body_vel_batch:\", body_vel_batch.shape, body_vel_batch)\n",
    "    cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bca5b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:22:57.477120Z",
     "start_time": "2024-04-17T07:22:57.452974Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRU test\n",
    "rnn = nn.GRU(input_size=8, hidden_size=20, num_layers=1)   \n",
    "# obs 维度： sequence length, batch size, input size\n",
    "obs = torch.randn(5, 2, 8)\n",
    "# hidden state 维度： num_layers, batch size, hidden_size\n",
    "h0 = torch.randn(1, 2, 20)\n",
    "output, hn = rnn(obs, h0)\n",
    "print(\"obs:\\n\", obs)\n",
    "print(\"output:\", output.shape, \"\\n\", output)\n",
    "print(\"hn:\", hn.shape, \"\\n\", hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65937ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T08:54:16.835184Z",
     "start_time": "2024-04-17T08:54:16.829095Z"
    }
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([[[1, 2],\n",
    "                   [3, 4]],\n",
    "                  [[5, 6],\n",
    "                   [7, 8]]])\n",
    "print(t.shape)\n",
    "c = t.flatten(0,1)\n",
    "print(c.shape)\n",
    "print(t)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e629a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
